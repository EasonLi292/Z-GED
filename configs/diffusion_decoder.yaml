# Configuration for Diffusion-based Circuit Decoder Training

# Model Architecture
model:
  # Encoder (will be loaded from pretrained checkpoint)
  encoder:
    node_feature_dim: 4
    edge_feature_dim: 7
    gnn_hidden_dim: 64
    gnn_num_layers: 3
    latent_dim: 8
    topo_latent_dim: 2
    values_latent_dim: 2
    pz_latent_dim: 4
    dropout: 0.1

  # Diffusion Decoder
  decoder:
    hidden_dim: 256              # Hidden dimension for transformer
    num_layers: 6                # Number of transformer layers
    num_heads: 8                 # Number of attention heads
    latent_dim: 8                # Latent code dimension from encoder
    conditions_dim: 2            # Specifications dimension (cutoff, Q)
    max_nodes: 5                 # Maximum number of nodes
    max_poles: 4                 # Maximum number of poles
    max_zeros: 4                 # Maximum number of zeros
    dropout: 0.1                 # Dropout probability
    timesteps: 1000              # Number of diffusion timesteps

# Training Configuration
training:
  # Two-phase training
  phase1_epochs: 100             # Freeze encoder, train diffusion only
  phase2_epochs: 100             # Joint fine-tuning
  total_epochs: 200              # Total training epochs

  batch_size: 4                  # Batch size
  learning_rate_phase1: 1.0e-4   # Learning rate for phase 1
  learning_rate_phase2: 5.0e-5   # Learning rate for phase 2 (joint)

  weight_decay: 1.0e-5           # L2 regularization
  grad_clip: 1.0                 # Gradient clipping

  # Loss curriculum (gradually increase TF weight)
  tf_weight_start: 0.1           # Transfer function loss weight at start
  tf_weight_end: 1.0             # Transfer function loss weight at end
  tf_weight_warmup_epochs: 150   # Epochs to reach full TF weight

# Loss Weights
loss:
  # Diffusion loss components
  node_type_weight: 1.0          # Node type prediction
  edge_exist_weight: 1.0         # Edge existence prediction
  edge_value_weight: 1.0         # Edge value prediction
  pole_count_weight: 1.0         # Pole count prediction
  zero_count_weight: 1.0         # Zero count prediction
  pole_value_weight: 1.0         # Pole value prediction
  zero_value_weight: 1.0         # Zero value prediction

  # Transfer function loss (from existing VariableLengthTransferFunctionLoss)
  tf_weight: 0.5                 # Overall TF loss weight (will be modulated by curriculum)

  # Structural validity
  structure_weight: 0.1          # Structural constraint loss

  # Use time-dependent weighting
  use_time_weighting: true       # Early t: structure, late t: values

# Data Configuration
data:
  dataset_path: 'rlc_dataset/filter_dataset.pkl'
  train_split: 0.8               # 80% training, 20% validation

# Checkpoint Configuration
checkpoint:
  pretrained_encoder: 'checkpoints/variable_length/20251222_102121/best.pt'  # Pretrained encoder
  save_dir: 'checkpoints/diffusion_decoder'
  save_frequency: 10             # Save checkpoint every N epochs
  keep_best: true                # Keep best validation loss checkpoint

# Validation Configuration
validation:
  frequency: 1                   # Validate every N epochs
  num_samples: 10                # Number of samples to generate for visualization

# Logging Configuration
logging:
  log_frequency: 10              # Log metrics every N batches
  tensorboard: false             # Use TensorBoard logging
  verbose: true                  # Print detailed metrics
